{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7abdec1-bd8c-454f-b59a-e2c5b4d88d17",
   "metadata": {},
   "source": [
    "## Custom PTAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566fd743-f16d-45ba-83fc-d494cf371701",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad8b0c7d-a708-4e03-bf1e-9cdf66a42a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ptan import ptan\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4240db-df5e-487f-b5d1-7e543f72e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionSelector:\n",
    "    \"\"\"\n",
    "    Abstract class which converts scores to the actions\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, scores):\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46dcf89d-ddd3-439f-b190-2bf2ae1cdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgmaxActionSelector(ActionSelector):\n",
    "    \"\"\"\n",
    "    Selects actions using argmax\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, scores):\n",
    "        assert isinstance(scores, np.ndarray)\n",
    "        return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "856c80e8-7c8c-4468-8403-9eeee59867c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedsyActionSelector(ActionSelector):\n",
    "    def __init__(self, epsilon=0.05, selector=None):\n",
    "        self.epsilon = epsilon\n",
    "        self.selector = selector if selector is not None else ArgmaxActionSelector()\n",
    "\n",
    "    def __call__(self, scores):\n",
    "        assert isinstance(scores, np.ndarray)\n",
    "        batch_size, n_actions = scores.shape\n",
    "        actions = self.selector(scores)\n",
    "        mask = np.random.random(size=batch_size) < self.epsilon\n",
    "        # sum(mask) 개수만큼 random한 값 생성\n",
    "        rand_actions = np.random.choice(n_actions, sum(mask))\n",
    "        actions[mask] = rand_actions\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cec0c4a3-8a36-4b46-a50a-6d6df36b2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityActionSelector(ActionSelector):\n",
    "    def __call__(self, probs):\n",
    "        assert isinstance(probs, np.ndarray)\n",
    "        actions = []\n",
    "        for prob in probs:\n",
    "            actions.append(np.random.choice(len(prob), p=prob))\n",
    "        return np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf472ec7-b48b-4820-a190-8ba1a6f10fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilityActionSelector(ActionSelector):\n",
    "    \"\"\"\n",
    "    Converts probabilities of actions into action by sampling them\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, probs):\n",
    "        assert isinstance(probs, np.ndarray)\n",
    "        actions = []\n",
    "        for prob in probs:\n",
    "            actions.append(np.random.choice(len(prob), p=prob))\n",
    "        return np.array(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a9f74-f713-44d2-96b5-24b62f4948c4",
   "metadata": {},
   "source": [
    "## ArgmaxActionSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc0d5f5a-ceaa-48f8-9aac-141d2ebba237",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_vals = np.array([[1, 2, 3], [1, -1, 0], [0, -1, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ffa693e-0317-4229-90ba-ee470306bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ArgmaxActionSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "967cc212-3ec0-413a-95d3-1f744926ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = obj(q_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31770d78-d813-4567-9073-cb9121216e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf17609-fa9a-4c7b-a518-42ddd3a21314",
   "metadata": {},
   "source": [
    "## EpsilonGreedyActionSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6508ef91-8736-429a-94fc-a4c48d989049",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = EpsilonGreedsyActionSelector(epsilon=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b909f5fc-7f70-4a03-9b2f-5eb148a04328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj(q_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502679fa-6c40-44a1-b641-8b0561bfa65e",
   "metadata": {},
   "source": [
    "### Probability Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c162c855-fea5-431d-93f4-d6ce642b255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1]\n",
      "[1 2 0]\n",
      "[1 2 1]\n",
      "[1 2 0]\n",
      "[1 2 0]\n",
      "[1 2 0]\n",
      "[1 2 1]\n",
      "[1 2 0]\n",
      "[1 2 0]\n",
      "[1 2 1]\n"
     ]
    }
   ],
   "source": [
    "obj = ProbabilityActionSelector()\n",
    "for _ in range(10):\n",
    "    acts = obj(np.array([[0.1, 0.8, 0.1], [0.0, 0.0, 1.0], [0.5, 0.5, 0.0]]))\n",
    "    print(acts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c29978-6c81-4efb-9c56-be91d215551e",
   "metadata": {},
   "source": [
    "## Set Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "809a1b9a-a5a4-41d0-95e9-9932190339ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def initial_state(self):\n",
    "        return None\n",
    "\n",
    "    def __call__(self, states, agent_states):\n",
    "        assert isinstance(states, list)\n",
    "        assert isinstance(agent_states, list)\n",
    "        assert len(agent_states) == len(states)\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def default_states_preprocessor(states):\n",
    "    \"\"\"\n",
    "    Convert list of states into the form suitable for model. By default we assume Variable\n",
    "    :param states: list of numpy arrays with states\n",
    "    :return: Variable\n",
    "    \"\"\"\n",
    "    if len(states) == 1:\n",
    "        np_states = np.expand_dims(states[0], 0)\n",
    "    else:\n",
    "        np_states = np.array([np.array(s, copy=False) for s in states], copy=False)\n",
    "    return torch.tensor(np_states)\n",
    "\n",
    "\n",
    "def float32_preprocessor(states):\n",
    "    np_states = np.array(states, dtype=np.float32)\n",
    "    return torch.tensor(np_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1bb90131-4b3d-4696-a5d9-453551584b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(BaseAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dqn_model,\n",
    "        action_selector,\n",
    "        device=\"cpu\",\n",
    "        preprocessor=default_states_preprocessor,\n",
    "    ):\n",
    "        self.dqn_model = dqn_model\n",
    "        self.action_selector = action_selector\n",
    "        self.preprocessor = preprocessor\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, states, agent_states=None):\n",
    "        if agent_states is None:\n",
    "            agent_states = [None] * len(states)\n",
    "        if self.preprocessor is not None:\n",
    "            states = self.preprocessor(states)\n",
    "            if torch.is_tensor(states):\n",
    "                states = states.to(self.device)\n",
    "        q_v = self.dqn_model(states)\n",
    "        q = q_v.data.cpu().numpy()\n",
    "        actions = self.action_selector(q)\n",
    "        return actions, agent_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0eba9-3a5f-47dc-9df8-4245b23f4c56",
   "metadata": {},
   "source": [
    "### DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5283881f-6df9-4cad-9619-1b2276e10a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNNet(nn.Module):\n",
    "    def __init__(self, actions: int):\n",
    "        super().__init__()\n",
    "        self.actions = actions\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.eye(x.size()[0], self.actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfcbf021-4e67-449f-abaf-13ce9fc7a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch eye\n",
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0485d8b-864a-494e-b13f-50c652ba678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DQNNet(actions=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2faa8669-492f-4519-840b-41db97afb13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.zeros(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a12c9a99-6689-40ef-b686-0d0b69627344",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = EpsilonGreedsyActionSelector(epsilon=1.0)\n",
    "agent = DQNAgent(dqn_model=net, action_selector=selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3bf880bc-8ac0-4b1f-9446-d935147a8099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 1, 0, 0, 0, 1, 2, 1, 1]),\n",
       " [None, None, None, None, None, None, None, None, None, None])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(torch.zeros(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3b4ee63c-986d-4b40-9161-2eb9d0cb9beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.epsilone = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9ea930d6-9466-4a8e-95fa-cd37461a02d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 0, 1, 2, 0, 1, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(torch.zeros(10, 5))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49563b24-a37d-4996-b76f-677cea0b7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "51288555-46cd-4729-ae16-40886f16943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(torch.zeros(10, 5))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9958cafa-ea87-40e2-8062-e7fe24df3ae7",
   "metadata": {},
   "source": [
    "### Policy Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63d3fce3-286c-43d9-9667-0177dd7e3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyAgent(BaseAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        action_selector=ProbabilityActionSelector(),\n",
    "        device=\"cpu\",\n",
    "        apply_softmax=False,\n",
    "        preprocessor=default_states_preprocessor,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.action_selector = action_selector\n",
    "        self.device = device\n",
    "        self.apply_softmax = apply_softmax\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, states, agent_states=None):\n",
    "        if agent_states is None:\n",
    "            agent_states = [None] * len(states)\n",
    "        if self.preprocessor is not None:\n",
    "            states = self.preprocessor(states)\n",
    "            if torch.is_tensor(states):\n",
    "                states = states.to(self.device)\n",
    "        probs_v = self.model(states)\n",
    "        if self.apply_softmax:\n",
    "            probs_v = F.softmax(probs_v, dim=1)\n",
    "        probs = probs_v.data.cpu().numpy()\n",
    "        actions = self.action_selector(probs)\n",
    "        return np.array(actions), agent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3003850-261d-4f5a-be1c-d829a67480b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, actions: int):\n",
    "        super().__init__()\n",
    "        self.actions = actions\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = (x.size()[0], self.actions)\n",
    "        res = torch.zeros(shape, dtype=torch.float32)\n",
    "        res[:, 0] = 1\n",
    "        res[:, 1] = 1\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a79e6ffb-b1e5-4399-81ba-4019b3de95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PolicyNet(actions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac426c5e-1636-45c5-be83-e7601f660aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.zeros(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e043479d-4353-4462-9677-16c45e943ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = ProbabilityActionSelector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a068b3ad-4f0f-40d2-b3f5-e6d173f79d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PolicyAgent(model=net, action_selector=selector, apply_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f4f6546c-b4c7-4685-8d04-7102acc5b8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 3, 0, 1]), [None, None, None, None, None])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(torch.zeros(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a82b0-2436-4b01-9e16-d4305b6bafaf",
   "metadata": {},
   "source": [
    "## Toy Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "66d77c67-0ed1-4791-9081-cc2a87e39d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from typing import List, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ab94d10-4613-4b6c-a2ae-e78195dad1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = gym.spaces.Discrete(n=5)\n",
    "        self.action_space = gym.spaces.Discrete(n=3)\n",
    "        self.step_index = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_index = 0\n",
    "        return self.step_index\n",
    "\n",
    "    def step(self, action):\n",
    "        is_done = self.step_index == 10\n",
    "        if is_done:\n",
    "            return self.step_index % self.observation_space.n, 0.0, is_done, {}\n",
    "        self.step_index += 1\n",
    "        return (\n",
    "            self.step_index % self.observation_space.n,\n",
    "            float(action),\n",
    "            self.step_index == 10,\n",
    "            {},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "98c856b8-b9ad-4aec-a699-59271f427f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DullAgent(ptan.agent.BaseAgent):\n",
    "    def __init__(self, action: int):\n",
    "        self.action = action\n",
    "\n",
    "    def __call__(self, observations: List[Any], state: Optional[List] = None):\n",
    "        return [self.action for _ in observations], state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca5be7-f2d1-45c7-8464-3cfec3d1891f",
   "metadata": {},
   "source": [
    "## The Experience Source Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a0ec2ae-018a-42f5-8a5c-e03b8269f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ToyEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "044b8bcf-39e5-46af-bd3c-c9fa3ac6998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DullAgent(action=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f57e8416-b2f0-4f46-8c8d-aad6abdbd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_source = ptan.experience.ExperienceSource(env=env, agent=agent, steps_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a09a84df-1d20-429b-943e-05b0ce27bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
      "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
      "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n"
     ]
    }
   ],
   "source": [
    "for idx, exp in enumerate(exp_source):\n",
    "    if idx > 2:\n",
    "        break\n",
    "    print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "30828939-d7fa-48f9-a88a-73e6040e8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
      "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
      "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
      "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
      "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
      "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
      "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
      "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
      "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=True))\n",
      "(Experience(state=4, action=1, reward=1.0, done=True),)\n",
      "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n",
      "(Experience(state=1, action=1, reward=1.0, done=False), Experience(state=2, action=1, reward=1.0, done=False))\n",
      "(Experience(state=2, action=1, reward=1.0, done=False), Experience(state=3, action=1, reward=1.0, done=False))\n",
      "(Experience(state=3, action=1, reward=1.0, done=False), Experience(state=4, action=1, reward=1.0, done=False))\n",
      "(Experience(state=4, action=1, reward=1.0, done=False), Experience(state=0, action=1, reward=1.0, done=False))\n",
      "(Experience(state=0, action=1, reward=1.0, done=False), Experience(state=1, action=1, reward=1.0, done=False))\n"
     ]
    }
   ],
   "source": [
    "for idx, exp in enumerate(exp_source):\n",
    "    if idx > 15:\n",
    "        break\n",
    "    print(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c78e50-e560-4165-b481-c851bf571329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfff2fd-1d7d-471f-b43a-ec9b3ec66652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bbb23-c457-458d-b65f-d1ada5856569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fe797-118f-483d-b7e9-f8b0f89c83b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266be50-79b9-4619-8e45-c36da2eea12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45414ec6-354d-4be5-b701-cc8bc0defcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b55250-49e1-43d5-bb71-36a393f5c417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc753203-7ddb-4579-8f6e-29c2236c7721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77c8c3-79aa-475a-a843-79da8e2cc1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
